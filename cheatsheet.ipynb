{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kedro.config import OmegaConfigLoader\n",
    "from kedro.io import DataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juan_cano/.micromamba/envs/kedrohf311-talk/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "config_loader = OmegaConfigLoader(conf_source=\".\", base_env=\"\", default_run_env=\"\")\n",
    "catalog = DataCatalog.from_config(config_loader[\"catalog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = pipeline(\"fill-mask\", model=\"Twitter/twhin-bert-base\")\n",
    "fill_mask_model = catalog.load(\"fill_mask_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.08654018491506577,\n",
       "  'token': 166871,\n",
       "  'token_str': 'cycling',\n",
       "  'sequence': 'I have bought a new bike, I am so excited. #cycling'},\n",
       " {'score': 0.0704832673072815,\n",
       "  'token': 60142,\n",
       "  'token_str': 'bike',\n",
       "  'sequence': 'I have bought a new bike, I am so excited. #bike'},\n",
       " {'score': 0.04027479514479637,\n",
       "  'token': 712,\n",
       "  'token_str': 'ad',\n",
       "  'sequence': 'I have bought a new bike, I am so excited. #ad'},\n",
       " {'score': 0.020212598145008087,\n",
       "  'token': 210425,\n",
       "  'token_str': 'BMW',\n",
       "  'sequence': 'I have bought a new bike, I am so excited. #BMW'},\n",
       " {'score': 0.018154606223106384,\n",
       "  'token': 40972,\n",
       "  'token_str': 'EV',\n",
       "  'sequence': 'I have bought a new bike, I am so excited. #EV'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask_model(\"I have bought a new bike, I am so excited. #<mask>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashtags(sentence, model, num_hashtags=5, mask_token=\"<mask>\"):\n",
    "    sentence_placeholder = sentence + f\" #{mask_token}\"\n",
    "    if sentence_placeholder.count(mask_token) > 1:\n",
    "        raise ValueError(f\"Do not include '{mask_token} in the input sentence\")\n",
    "\n",
    "    fill_results = model(sentence_placeholder, top_k=num_hashtags)\n",
    "    hashtag_results = [{\n",
    "        \"hashtag_str\": result[\"token_str\"],\n",
    "        \"score\": result[\"score\"]\n",
    "    } for result in fill_results]\n",
    "\n",
    "    return sorted(hashtag_results, key=lambda res: -res[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hashtag_str': 'ad', 'score': 0.05545256286859512},\n",
       " {'hashtag_str': 'cycling', 'score': 0.030171526595950127},\n",
       " {'hashtag_str': 'BMW', 'score': 0.02008751407265663},\n",
       " {'hashtag_str': 'Apple', 'score': 0.019576990976929665},\n",
       " {'hashtag_str': 'road', 'score': 0.018990855664014816}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hashtags(\"I have bought a new bicycle, I am so excited.\", fill_mask_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_post = \"\"\"McKinsey doubles down on open source üî•\n",
    "\n",
    "Today, we're thrilled to announce McKinsey & Company new GitHub organization, hosting cutting-edge technologies created inside the Firm. With it, we are also open sourcing Vizro, a toolkit for creating modular data visualization applications.\n",
    "\n",
    "Open source is not new for McKinsey: Kedro and CausalNex have been developed in the open since 2019 and 2020 respectively, and Kedro was donated to LF AI & Data Foundation in 2021 as a commitment to evolve it as an open standard. In addition, McKinsey acquired Iguazio (Acquired by McKinsey) in early 2023 and brought Nuclio and MLRun, both open source components underpinning the Iguazio platform.\n",
    "\n",
    "I'm so excited to be part of the Firm at this moment, bringing my open source expertise to a huge organization and working side by side with brilliant professionals. I'm positive all of this wouldn't have been possible without the relentless work of Yetunde Dada, distinguised product manager and a daily source of inspiration.\n",
    "\n",
    "In words of Rodney W. Zemmel, senior partner and global leader of McKinsey Digital, ‚Äúwe are on a journey to be known for our technology capabilities as much as our strategic advice‚Äù.\n",
    "\n",
    "Let's go!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "#¬†summarizer = pipeline(\"summarization\")\n",
    "summarizer_pipe = catalog.load(\"summarizer_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' McKinsey doubles down on open source . New GitHub organization hosts cutting-edge technologies created inside the Firm . McKinsey acquired Iguazio (Acquired by McKinsey) in early 2023 and brought Nuclio and MLRun, both open source components'},\n",
       " {'summary_text': ' McKinsey doubles down on open source . New GitHub organization hosts cutting-edge technologies created inside the Firm . McKinsey acquired Iguazio (Acquired by McKinsey) in early 2023 and brought Nuclio and MLRun, both open source components'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_pipe([linkedin_post, linkedin_post], max_length=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(text, model):\n",
    "    if not isinstance(text, str):\n",
    "        raise ValueError(\"Pass a single string\")\n",
    "\n",
    "    summary_results = model(text)\n",
    "    return summary_results[0][\"summary_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' McKinsey doubles down on open source . New GitHub organization hosts cutting-edge technologies created inside the Firm . McKinsey acquired Iguazio (Acquired by McKinsey) in early 2023 and brought Nuclio and MLRun, both open source components underpinning the platform .'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_summary(linkedin_post, summarizer_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hashtag_str': 'tech', 'score': 0.06541883200407028},\n",
       " {'hashtag_str': 'data', 'score': 0.05542179197072983},\n",
       " {'hashtag_str': 'innovation', 'score': 0.03917607665061951},\n",
       " {'hashtag_str': 'ad', 'score': 0.03191298246383667},\n",
       " {'hashtag_str': 'AI', 'score': 0.028968561440706253}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hashtags(_25, fill_mask_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hashtag_str': 'tech', 'score': 0.07206881791353226},\n",
       " {'hashtag_str': 'data', 'score': 0.061998412013053894},\n",
       " {'hashtag_str': 'innovation', 'score': 0.047728437930345535},\n",
       " {'hashtag_str': 'AI', 'score': 0.03327333182096481},\n",
       " {'hashtag_str': 'marketing', 'score': 0.032877687364816666}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hashtags(_25.replace(\"open source\", \"open-source\"), fill_mask_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_post_es = \"\"\"Si buscas una carrera como Data Scientist en Espa√±a, el informe de Manfred tiene malas noticias para ti...\n",
    "\n",
    "\"Data Scientist\" es literalmente el rol menos demandado de los que aparecen en la encuesta, con un 0.5 %. (El segundo menos demandado es Product Manager, ups üò¨)\n",
    "\n",
    "Sin √°nimo de extrapolar conclusiones apresuradas, esto \"se ve√≠a venir\": el rol de Data Scientist como se imagin√≥ a principios de la d√©cada pasada (ese unicornio en el centro de un diagrama de Venn infinito) ya no existe, la industria ha madurado, y se ha visto que hace falta mucho data engineering para siquiera poder hacer un poco de data analysis en condiciones, no digamos ya data science.\n",
    "\n",
    "¬øQu√© opinas?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /Users/juan_cano/.micromamba/envs/kedrohf311-talk/lib/python3.11/site-packages (0.1.99)\n",
      "Collecting protobuf\n",
      "  Obtaining dependency information for protobuf from https://files.pythonhosted.org/packages/fe/f3/957db80e5b9f7fd7df97e5554fdc57919dfad24e89291223fd04a0e3c84f/protobuf-4.24.3-cp37-abi3-macosx_10_9_universal2.whl.metadata\n",
      "  Using cached protobuf-4.24.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (540 bytes)\n",
      "Using cached protobuf-4.24.3-cp37-abi3-macosx_10_9_universal2.whl (409 kB)\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-4.24.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentencepiece protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_es_pipe = catalog.load(\"spanish_summarizer_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'En Espa√±a, el informe de Manfred tiene malas noticias para ti... \"Data Scientist\" es literalmente el rol menos demandado.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_es_pipe(linkedin_post_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \"Data Scientist\" is el rol menos demandado de los que aparecen en la encuesta, with un 0.5% demandado . La industria ha madurado, and se ha visto that hace falta mucho mucho poder hacer un poco de data engineering .'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_summary(linkedin_post_es, summarizer_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_es_results = summarizer(linkedin_post_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "longform_sentiment_pipe = catalog.load(\"longform.sentiment_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (‚Ä¶)lve/main/config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.00k/1.00k [00:00<00:00, 5.55MB/s]\n",
      "Downloading pytorch_model.bin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 329M/329M [00:11<00:00, 29.8MB/s] \n",
      "Downloading (‚Ä¶)okenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 294/294 [00:00<00:00, 445kB/s]\n",
      "Downloading (‚Ä¶)olve/main/vocab.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 798k/798k [00:00<00:00, 2.65MB/s]\n",
      "Downloading (‚Ä¶)olve/main/merges.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 456k/456k [00:00<00:00, 3.22MB/s]\n",
      "Downloading (‚Ä¶)/main/tokenizer.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.36M/1.36M [00:00<00:00, 5.49MB/s]\n",
      "Downloading (‚Ä¶)cial_tokens_map.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 239/239 [00:00<00:00, 1.02MB/s]\n"
     ]
    }
   ],
   "source": [
    "shortform_sentiment_pipe = catalog.load(\"shortform.sentiment_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.9231044054031372}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longform_sentiment_pipe(linkedin_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'joy', 'score': 0.8978003263473511}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortform_sentiment_pipe(linkedin_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'joy', 'score': 0.8978003263473511}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortform_sentiment_pipe(linkedin_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (‚Ä¶)lve/main/config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.42k/1.42k [00:00<00:00, 10.7MB/s]\n",
      "Downloading pytorch_model.bin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.11G/1.11G [00:40<00:00, 27.5MB/s]\n",
      "Downloading (‚Ä¶)okenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 502/502 [00:00<00:00, 1.44MB/s]\n",
      "Downloading (‚Ä¶)tencepiece.bpe.model: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.07M/5.07M [00:00<00:00, 7.02MB/s]\n",
      "Downloading (‚Ä¶)/main/tokenizer.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.08M/9.08M [00:00<00:00, 10.6MB/s]\n",
      "Downloading (‚Ä¶)cial_tokens_map.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 239/239 [00:00<00:00, 983kB/s]\n"
     ]
    }
   ],
   "source": [
    "language_detector_pipe = catalog.load(\"language_detector_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'en', 'score': 0.9330440163612366}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_detector_pipe(linkedin_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'es', 'score': 0.9917725920677185}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_detector_pipe(linkedin_post_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
